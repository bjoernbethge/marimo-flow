name: Claude Code with MCP Integration

on:
  issue_comment:
    types: [created]
  pull_request_review_comment:
    types: [created]
  issues:
    types: [opened]
  pull_request:
    types: [opened, synchronize]

jobs:
  claude:
    # Trigger on @claude mentions or new PRs
    if: |
      (github.event_name == 'issue_comment' && contains(github.event.comment.body, '@claude')) ||
      (github.event_name == 'pull_request_review_comment' && contains(github.event.comment.body, '@claude')) ||
      (github.event_name == 'issues' && contains(github.event.issue.body, '@claude')) ||
      github.event_name == 'pull_request'

    runs-on: ubuntu-latest
    timeout-minutes: 30

    permissions:
      contents: write
      issues: write
      pull-requests: write

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Setup uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"

      - name: Install Dependencies
        run: |
          # Install core dependencies with MCP support
          uv pip install --system "marimo[mcp]>=0.18.0"
          uv pip install --system "mlflow[mcp]>=2.19.0"

          # Install project dependencies
          uv sync --no-dev

      - name: Setup MLflow Backend
        run: |
          # Create MLflow directories
          mkdir -p data/mlflow/{db,artifacts}

          # Initialize SQLite database if needed
          if [ ! -f data/mlflow/db/mlflow.db ]; then
            echo "Initializing MLflow database..."
            touch data/mlflow/db/mlflow.db
          fi

          # Start MLflow server in background
          mlflow server \
            --host 0.0.0.0 \
            --port 5000 \
            --backend-store-uri sqlite:///$(pwd)/data/mlflow/db/mlflow.db \
            --default-artifact-root $(pwd)/data/mlflow/artifacts \
            --serve-artifacts &

          # Wait for MLflow to be ready
          echo "Waiting for MLflow server..."
          for i in {1..30}; do
            if curl -s http://localhost:5000/health > /dev/null 2>&1; then
              echo "✅ MLflow server ready!"
              break
            fi
            sleep 1
          done

      - name: Start Marimo MCP Server
        run: |
          # Start Marimo with MCP support (headless mode for CI)
          marimo edit examples/ \
            --mcp \
            --no-token \
            --headless \
            --host 0.0.0.0 \
            --port 2718 &

          # Wait for Marimo MCP server to be ready
          echo "Waiting for Marimo MCP server..."
          for i in {1..30}; do
            if curl -s http://localhost:2718/mcp/server > /dev/null 2>&1; then
              echo "✅ Marimo MCP server ready!"
              break
            fi
            sleep 1
          done

      - name: Start MLflow MCP Server
        run: |
          # Start MLflow MCP server in background
          export MLFLOW_TRACKING_URI=http://localhost:5000
          mlflow mcp run &

          # Give it a moment to initialize
          sleep 3
          echo "✅ MLflow MCP server started!"

      - name: Run Claude Code
        uses: anthropics/claude-code-action@v1
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}

          # MCP Server Configuration
          # 1. marimo: Notebook introspection and cell analysis
          # 2. context7: Live documentation for Python libraries
          # 3. mlflow: Experiment tracking and model management
          mcp_servers: |
            [
              {
                "name": "marimo",
                "transport": "http",
                "url": "http://localhost:2718/mcp/server"
              },
              {
                "name": "context7",
                "transport": "sse",
                "url": "https://context7.com/api/v1/mcp/sse"
              },
              {
                "name": "mlflow",
                "transport": "stdio",
                "command": "mlflow",
                "args": ["mcp", "run"],
                "env": {
                  "MLFLOW_TRACKING_URI": "http://localhost:5000"
                }
              }
            ]

          # Allowed Tools - All MCP tools + standard Claude Code tools
          allowed_tools: |
            mcp__marimo__get_active_notebooks
            mcp__marimo__get_notebook_errors
            mcp__marimo__get_cell_runtime_data
            mcp__marimo__get_tables_and_variables
            mcp__marimo__get_database_tables
            mcp__marimo__get_lightweight_cell_map
            mcp__marimo__get_marimo_rules
            mcp__context7__search_docs
            mcp__context7__get_library_docs
            mcp__mlflow__search_experiments
            mcp__mlflow__get_experiment
            mcp__mlflow__search_runs
            mcp__mlflow__get_run
            mcp__mlflow__log_metric
            mcp__mlflow__log_param
            mcp__mlflow__list_models
            mcp__mlflow__get_model_version
            Edit
            Read
            Write
            Bash
            Glob
            Grep
            WebSearch

          # Custom Instructions for marimo-flow
          custom_instructions: |
            You are working in the **marimo-flow** repository using a **multi-agent architecture** based on Cursor's research.

            ## Agent Architecture

            Use **hierarchical agent roles** (Planner → Workers → Judge):

            **When you need to PLAN**:
            - Read: `.github/agents/planner-agent.md`
            - Explore codebase, break down requirements into tasks
            - Create focused tasks for Workers
            - Don't implement yourself

            **When you need to IMPLEMENT**:
            - Read appropriate Worker agent file:
              - `.github/agents/worker-notebook.md` - Marimo notebooks
              - `.github/agents/worker-mlflow.md` - Experiment tracking
              - `.github/agents/worker-pina.md` - Physics-informed neural networks
              - `.github/agents/worker-data.md` - Polars/DuckDB data processing
              - `.github/agents/worker-testing.md` - pytest tests
            - Take task and execute autonomously
            - Push results when done
            - Self-coordinate on conflicts

            **When you need to REVIEW**:
            - Read: `.github/agents/judge-agent.md`
            - Evaluate work against acceptance criteria
            - Decide: Ship | Iterate | Escalate
            - Don't implement fixes yourself

            **Architecture Details**: `.github/agents/README.md`

            ### Core Principles (from Cursor Research)
            1. **Clear role separation** - Don't mix planning/execution/judgment
            2. **Reduce complexity** - Workers handle conflicts without integrators
            3. **Own hard problems** - Take responsibility end-to-end
            4. **Prompts > Infrastructure** - Detailed prompts matter most

            ## Project Context
            - **Marimo**: Reactive Python notebooks (`.py` files, git-friendly)
            - **MLflow**: ML experiment tracking and model registry
            - **PINA**: Physics-Informed Neural Networks
            - **Stack**: Polars (data), Altair/Plotly (viz), DuckDB (analytics)

            ## MCP Tools Available

            ### Marimo MCP (Notebook Introspection)
            - `get_active_notebooks`: List all open notebooks
            - `get_notebook_errors`: Find runtime errors in cells
            - `get_cell_runtime_data`: Inspect cell execution state
            - `get_tables_and_variables`: Analyze DataFrames and variables
            - `get_database_tables`: Inspect DuckDB/SQL connections

            ### Context7 MCP (Live Documentation)
            - `search_docs`: Find docs for any Python library
            - `get_library_docs`: Get comprehensive library reference
            - Use for: Polars, Plotly, Altair, Marimo, scikit-learn, PyTorch

            ### MLflow MCP (Experiment Tracking)
            - `search_experiments`: Find ML experiments
            - `search_runs`: Query training runs
            - `log_metric/log_param`: Track experiments
            - `list_models`: Browse model registry

            ## Workflow Guidelines

            ### Identify Your Role First
            1. **User asks for planning/architecture** → Act as Planner Agent
            2. **You're given a specific task** → Act as appropriate Worker Agent
            3. **You're asked to review code** → Act as Judge Agent

            ### When Acting as Planner
            - Explore codebase with MCP tools (`get_active_notebooks`, `search_docs`)
            - Break down into focused tasks
            - Assign tasks to Workers (notebook/mlflow/pina/data/testing)
            - Don't implement code yourself

            ### When Acting as Worker
            - Follow specialist patterns in worker-*.md files
            - Marimo: Reactivity, idempotent cells, unique names
            - MLflow: Check existing experiments, use context managers
            - PINA: Correct PDE formulation, boundary conditions
            - Data: Polars > Pandas, lazy evaluation
            - Testing: pytest, >80% coverage, edge cases

            ### When Acting as Judge
            - Check requirements met
            - Validate code quality (reactivity, type hints, docstrings)
            - Decide: Ship (approve) | Iterate (fix) | Escalate (planner)
            - Don't re-implement, delegate back to Worker

            ## Critical Patterns

            ### Reactivity (Marimo)
            ```python
            # ✅ Good - idempotent, unique names
            data_raw = pl.read_csv("data.csv")
            data_filtered = data_raw.filter(pl.col("age") > 18)

            # ❌ Bad - mutation breaks reactivity
            data = pl.read_csv("data.csv")
            data = data.filter(...)  # Reuses variable!
            ```

            ### MLflow Integration
            ```python
            # Always check for existing experiment
            existing = mlflow.search_experiments(filter_string=f"name = '{name}'")
            exp_id = existing[0].experiment_id if existing else mlflow.create_experiment(name)

            # Use context managers
            if mlflow.active_run():
                mlflow.end_run()

            with mlflow.start_run(experiment_id=exp_id):
                mlflow.log_params({...})
                mlflow.log_metrics({...})
            ```

            ### Data Processing
            ```python
            # Prefer Polars (10-100x faster)
            df = pl.scan_csv("data.csv").filter(...).select(...).collect()

            # Or DuckDB for SQL
            result = duckdb.execute("SELECT * FROM 'data.csv' WHERE age > 18").pl()
            ```

            ## Directory Structure
            - `.github/agents/` - **Agent architecture documentation (READ THESE FIRST)**
            - `examples/` - Production notebooks (01-09 + tutorials/)
            - `snippets/` - Reusable modules for import
            - `data/mlflow/` - Experiment tracking storage
            - `docs/` - Reference documentation

            ## Anti-Patterns (from Cursor Research)
            - ❌ Mixing roles (planning + implementing)
            - ❌ Waiting for integrator (workers self-coordinate)
            - ❌ Avoiding hard problems (own them end-to-end)
            - ❌ Adding complexity (keep it simple)

            **Remember**: Read the appropriate agent file (`.github/agents/`) for your current role before taking action. The agent architecture is your primary guide.

      - name: Verify Services Running
        if: failure()
        run: |
          echo "=== Service Status ==="
          echo "MLflow:"
          curl -f http://localhost:5000/health || echo "❌ MLflow not responding"
          echo ""
          echo "Marimo MCP:"
          curl -f http://localhost:2718/mcp/server || echo "❌ Marimo MCP not responding"
          echo ""
          echo "=== Logs ==="
          jobs -l
          ps aux | grep -E "mlflow|marimo"
