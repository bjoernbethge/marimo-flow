"""
Configuration Management Template

Provides patterns for managing experiment configurations across different
frameworks and use cases.

Usage:
1. Choose configuration pattern (dataclass, dict, YAML, etc.)
2. Customize fields for your use case
3. Add validation logic
4. Integrate with your training pipeline
"""

from dataclasses import dataclass, field, asdict
from typing import List, Optional, Dict, Any
from pathlib import Path
import yaml
import json


# ============================================================================
# Pattern 1: Dataclass Configuration (Recommended)
# ============================================================================

@dataclass
class ModelConfig:
    """Model architecture configuration."""
    input_dim: int
    output_dim: int
    hidden_dims: List[int] = field(default_factory=lambda: [64, 64])
    activation: str = "relu"
    dropout: float = 0.0
    batch_norm: bool = False

    def validate(self):
        """Validate configuration."""
        assert self.input_dim > 0, "input_dim must be positive"
        assert self.output_dim > 0, "output_dim must be positive"
        assert 0 <= self.dropout < 1, "dropout must be in [0, 1)"
        assert all(h > 0 for h in self.hidden_dims), "hidden_dims must be positive"


@dataclass
class TrainingConfig:
    """Training hyperparameters."""
    batch_size: int = 32
    learning_rate: float = 0.001
    max_epochs: int = 100
    optimizer: str = "adam"
    loss_function: str = "mse"
    weight_decay: float = 0.0
    gradient_clip: Optional[float] = None

    # Scheduler
    use_scheduler: bool = False
    scheduler_type: str = "step"
    scheduler_params: Dict[str, Any] = field(default_factory=dict)

    # Early stopping
    early_stopping: bool = False
    patience: int = 10
    min_delta: float = 1e-4

    def validate(self):
        """Validate configuration."""
        assert self.batch_size > 0, "batch_size must be positive"
        assert self.learning_rate > 0, "learning_rate must be positive"
        assert self.max_epochs > 0, "max_epochs must be positive"
        assert self.weight_decay >= 0, "weight_decay must be non-negative"


@dataclass
class DataConfig:
    """Data loading configuration."""
    data_path: Path
    train_split: float = 0.8
    val_split: float = 0.1
    test_split: float = 0.1
    shuffle: bool = True
    num_workers: int = 0
    pin_memory: bool = False

    def validate(self):
        """Validate configuration."""
        total = self.train_split + self.val_split + self.test_split
        assert abs(total - 1.0) < 1e-6, f"Splits must sum to 1.0, got {total}"
        assert self.num_workers >= 0, "num_workers must be non-negative"


@dataclass
class ExperimentConfig:
    """Complete experiment configuration."""
    name: str
    model: ModelConfig
    training: TrainingConfig
    data: DataConfig

    # Paths
    output_dir: Path = Path("outputs")
    checkpoint_dir: Optional[Path] = None
    log_dir: Optional[Path] = None

    # Device
    device: str = "cpu"
    seed: int = 42

    # Logging
    log_interval: int = 10
    save_interval: int = 50

    # MLflow
    use_mlflow: bool = False
    mlflow_experiment: str = "default"
    mlflow_tracking_uri: Optional[str] = None

    def __post_init__(self):
        """Initialize paths and validate."""
        # Set default paths
        if self.checkpoint_dir is None:
            self.checkpoint_dir = self.output_dir / "checkpoints"
        if self.log_dir is None:
            self.log_dir = self.output_dir / "logs"

        # Create directories
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        self.log_dir.mkdir(parents=True, exist_ok=True)

        # Validate all sub-configs
        self.model.validate()
        self.training.validate()
        self.data.validate()

    def to_dict(self) -> dict:
        """Convert to dictionary."""
        return asdict(self)

    def to_yaml(self, path: Path):
        """Save configuration to YAML file."""
        with open(path, 'w') as f:
            yaml.dump(self.to_dict(), f, default_flow_style=False)

    def to_json(self, path: Path):
        """Save configuration to JSON file."""
        with open(path, 'w') as f:
            json.dump(self.to_dict(), f, indent=2)

    @classmethod
    def from_yaml(cls, path: Path) -> 'ExperimentConfig':
        """Load configuration from YAML file."""
        with open(path, 'r') as f:
            config_dict = yaml.safe_load(f)
        return cls.from_dict(config_dict)

    @classmethod
    def from_json(cls, path: Path) -> 'ExperimentConfig':
        """Load configuration from JSON file."""
        with open(path, 'r') as f:
            config_dict = json.load(f)
        return cls.from_dict(config_dict)

    @classmethod
    def from_dict(cls, config_dict: dict) -> 'ExperimentConfig':
        """Create configuration from dictionary."""
        # Convert nested dicts to dataclasses
        model_config = ModelConfig(**config_dict['model'])
        training_config = TrainingConfig(**config_dict['training'])
        data_config = DataConfig(
            data_path=Path(config_dict['data']['data_path']),
            **{k: v for k, v in config_dict['data'].items() if k != 'data_path'}
        )

        # Convert paths
        output_dir = Path(config_dict['output_dir'])
        checkpoint_dir = Path(config_dict['checkpoint_dir']) if config_dict.get('checkpoint_dir') else None
        log_dir = Path(config_dict['log_dir']) if config_dict.get('log_dir') else None

        return cls(
            name=config_dict['name'],
            model=model_config,
            training=training_config,
            data=data_config,
            output_dir=output_dir,
            checkpoint_dir=checkpoint_dir,
            log_dir=log_dir,
            device=config_dict.get('device', 'cpu'),
            seed=config_dict.get('seed', 42),
            log_interval=config_dict.get('log_interval', 10),
            save_interval=config_dict.get('save_interval', 50),
            use_mlflow=config_dict.get('use_mlflow', False),
            mlflow_experiment=config_dict.get('mlflow_experiment', 'default'),
            mlflow_tracking_uri=config_dict.get('mlflow_tracking_uri'),
        )


# ============================================================================
# Pattern 2: Nested Dictionary Configuration
# ============================================================================

def create_config_dict() -> dict:
    """
    Create configuration as nested dictionary.

    Simpler but less type-safe than dataclasses.
    """
    return {
        "name": "my_experiment",
        "model": {
            "input_dim": 10,
            "output_dim": 1,
            "hidden_dims": [64, 64],
            "activation": "relu",
            "dropout": 0.1,
        },
        "training": {
            "batch_size": 32,
            "learning_rate": 0.001,
            "max_epochs": 100,
            "optimizer": "adam",
        },
        "data": {
            "data_path": "data/dataset.csv",
            "train_split": 0.8,
            "val_split": 0.1,
        },
        "device": "cpu",
        "seed": 42,
    }


# ============================================================================
# Pattern 3: Configuration Builder Pattern
# ============================================================================

class ConfigBuilder:
    """
    Fluent interface for building configurations.

    Provides method chaining for readable configuration construction.
    """

    def __init__(self, name: str):
        self.config = {"name": name}

    def with_model(
        self,
        input_dim: int,
        output_dim: int,
        hidden_dims: List[int] = [64, 64],
        **kwargs
    ) -> 'ConfigBuilder':
        """Configure model architecture."""
        self.config["model"] = {
            "input_dim": input_dim,
            "output_dim": output_dim,
            "hidden_dims": hidden_dims,
            **kwargs
        }
        return self

    def with_training(
        self,
        batch_size: int = 32,
        learning_rate: float = 0.001,
        max_epochs: int = 100,
        **kwargs
    ) -> 'ConfigBuilder':
        """Configure training parameters."""
        self.config["training"] = {
            "batch_size": batch_size,
            "learning_rate": learning_rate,
            "max_epochs": max_epochs,
            **kwargs
        }
        return self

    def with_data(
        self,
        data_path: str,
        train_split: float = 0.8,
        **kwargs
    ) -> 'ConfigBuilder':
        """Configure data loading."""
        self.config["data"] = {
            "data_path": data_path,
            "train_split": train_split,
            **kwargs
        }
        return self

    def with_device(self, device: str) -> 'ConfigBuilder':
        """Set device."""
        self.config["device"] = device
        return self

    def with_mlflow(
        self,
        experiment: str = "default",
        tracking_uri: Optional[str] = None
    ) -> 'ConfigBuilder':
        """Enable MLflow tracking."""
        self.config["use_mlflow"] = True
        self.config["mlflow_experiment"] = experiment
        if tracking_uri:
            self.config["mlflow_tracking_uri"] = tracking_uri
        return self

    def build(self) -> dict:
        """Build final configuration."""
        return self.config


# ============================================================================
# Example Usage
# ============================================================================

if __name__ == "__main__":
    # Example 1: Using dataclass configuration
    print("=== Dataclass Configuration ===")

    config = ExperimentConfig(
        name="my_experiment",
        model=ModelConfig(
            input_dim=10,
            output_dim=1,
            hidden_dims=[64, 64, 32],
            dropout=0.1
        ),
        training=TrainingConfig(
            batch_size=32,
            learning_rate=0.001,
            max_epochs=100,
            early_stopping=True
        ),
        data=DataConfig(
            data_path=Path("data/dataset.csv"),
            train_split=0.8,
            val_split=0.1,
            test_split=0.1
        ),
        device="cpu",
        use_mlflow=True
    )

    print(f"Config name: {config.name}")
    print(f"Output dir: {config.output_dir}")

    # Save to YAML
    config.to_yaml(Path("config.yaml"))
    print("Saved to config.yaml")

    # Load from YAML
    loaded_config = ExperimentConfig.from_yaml(Path("config.yaml"))
    print(f"Loaded config: {loaded_config.name}")

    # Example 2: Using builder pattern
    print("\n=== Builder Pattern ===")

    config2 = (
        ConfigBuilder("builder_experiment")
        .with_model(input_dim=10, output_dim=1, hidden_dims=[128, 128])
        .with_training(batch_size=64, learning_rate=0.0001, max_epochs=200)
        .with_data(data_path="data/train.csv", train_split=0.9)
        .with_device("cuda")
        .with_mlflow(experiment="my_mlflow_exp")
        .build()
    )

    print(f"Built config: {config2['name']}")
    print(f"MLflow enabled: {config2['use_mlflow']}")

    # Example 3: Simple dict configuration
    print("\n=== Dictionary Configuration ===")

    config3 = create_config_dict()
    print(f"Dict config keys: {list(config3.keys())}")
